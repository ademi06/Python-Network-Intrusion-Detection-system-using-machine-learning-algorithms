{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30d6d183-38a4-4a6c-ae2b-a46db4e2fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing\n",
    "import matplotlib.pyplot as plt # Visualization\n",
    "import seaborn as sns #data visualization\n",
    "import time\n",
    "import sklearn.metrics as m #predictive data analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d03ce1-820b-4985-b110-16aebb3e6204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... \n",
      "Found conflicts! Looking for incompatible packages.\n",
      "This can take several minutes.  Press CTRL-C to abort.\n",
      "failed\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Building graph of deps:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Examining @/win-64::__archspec==1=x86_64:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Examining @/win-64::__cuda==11.2=0:  20%|##        | 1/5 [00:00<?, ?it/s]      \n",
      "Examining @/win-64::__win==0=0:  40%|####      | 2/5 [00:00<?, ?it/s]    \n",
      "Examining python=3.9:  60%|######    | 3/5 [00:00<?, ?it/s]          \n",
      "Examining imbalanced-learn:  80%|########  | 4/5 [00:00<00:00, 67.67it/s]\n",
      "                                                                         \n",
      "\n",
      "Determining conflicts:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "Examining conflict for python imbalanced-learn:   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "                                                                                     \n",
      "\n",
      "UnsatisfiableError: The following specifications were found\n",
      "to be incompatible with the existing python installation in your environment:\n",
      "\n",
      "Specifications:\n",
      "\n",
      "  - imbalanced-learn -> python[version='2.7.*|3.4.*|3.5.*|3.6.*']\n",
      "\n",
      "Your python: python=3.9\n",
      "\n",
      "If python is on the left-most side of the chain, that's the version you've asked for.\n",
      "When python appears to the right, that indicates that the thing on the left is somehow\n",
      "not available for the python version you are constrained to. Note that conda will not\n",
      "change your python version to a different minor version unless you explicitly specify\n",
      "that.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conda install -c glemaitre imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff475a6c-7334-4101-b123-fbd2a1e015da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in c:\\users\\bukola\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from imblearn) (0.8.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb46eaf-5ba2-476c-89dd-420f9d2d6239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import imblearn\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd3933f-1917-41ee-a9a6-44d2796d5499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 600100 entries, 0 to 600099\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   IPV4_SRC_ADDR               600100 non-null  object \n",
      " 1   L4_SRC_PORT                 600100 non-null  int64  \n",
      " 2   IPV4_DST_ADDR               600100 non-null  object \n",
      " 3   L4_DST_PORT                 600100 non-null  int64  \n",
      " 4   PROTOCOL                    600100 non-null  int64  \n",
      " 5   L7_PROTO                    600100 non-null  float64\n",
      " 6   IN_BYTES                    600100 non-null  int64  \n",
      " 7   OUT_BYTES                   600100 non-null  int64  \n",
      " 8   IN_PKTS                     600100 non-null  int64  \n",
      " 9   OUT_PKTS                    600100 non-null  int64  \n",
      " 10  TCP_FLAGS                   600100 non-null  int64  \n",
      " 11  FLOW_DURATION_MILLISECONDS  600100 non-null  int64  \n",
      " 12  Label                       600100 non-null  int64  \n",
      " 13  Attack                      600100 non-null  object \n",
      "dtypes: float64(1), int64(10), object(3)\n",
      "memory usage: 64.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "my_dataset=pd.read_csv(\"my_dataset.csv\")\n",
    "my_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ce8f95-3aca-4500-b639-80ca002addef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPV4_SRC_ADDR</th>\n",
       "      <th>L4_SRC_PORT</th>\n",
       "      <th>IPV4_DST_ADDR</th>\n",
       "      <th>L4_DST_PORT</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>FLOW_DURATION_MILLISECONDS</th>\n",
       "      <th>Label</th>\n",
       "      <th>Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.168.100.6</td>\n",
       "      <td>52670</td>\n",
       "      <td>192.168.100.1</td>\n",
       "      <td>53</td>\n",
       "      <td>17</td>\n",
       "      <td>5.212</td>\n",
       "      <td>71</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4294966</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.100.6</td>\n",
       "      <td>49160</td>\n",
       "      <td>192.168.100.149</td>\n",
       "      <td>4444</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>217753000</td>\n",
       "      <td>199100</td>\n",
       "      <td>4521</td>\n",
       "      <td>4049</td>\n",
       "      <td>24</td>\n",
       "      <td>4176249</td>\n",
       "      <td>1</td>\n",
       "      <td>Theft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.100.46</td>\n",
       "      <td>3456</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>80</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8508021</td>\n",
       "      <td>8918372</td>\n",
       "      <td>9086</td>\n",
       "      <td>9086</td>\n",
       "      <td>0</td>\n",
       "      <td>4175916</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.100.3</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.100.55</td>\n",
       "      <td>8080</td>\n",
       "      <td>6</td>\n",
       "      <td>7.000</td>\n",
       "      <td>8442138</td>\n",
       "      <td>9013406</td>\n",
       "      <td>9086</td>\n",
       "      <td>9086</td>\n",
       "      <td>0</td>\n",
       "      <td>4175916</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.100.46</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.100.5</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>7.000</td>\n",
       "      <td>8374706</td>\n",
       "      <td>0</td>\n",
       "      <td>9086</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4175916</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    IPV4_SRC_ADDR  L4_SRC_PORT    IPV4_DST_ADDR  L4_DST_PORT  PROTOCOL  \\\n",
       "0   192.168.100.6        52670    192.168.100.1           53        17   \n",
       "1   192.168.100.6        49160  192.168.100.149         4444         6   \n",
       "2  192.168.100.46         3456    192.168.100.5           80        17   \n",
       "3   192.168.100.3           80   192.168.100.55         8080         6   \n",
       "4  192.168.100.46           80    192.168.100.5           80         6   \n",
       "\n",
       "   L7_PROTO   IN_BYTES  OUT_BYTES  IN_PKTS  OUT_PKTS  TCP_FLAGS  \\\n",
       "0     5.212         71        126        1         1          0   \n",
       "1     0.000  217753000     199100     4521      4049         24   \n",
       "2     0.000    8508021    8918372     9086      9086          0   \n",
       "3     7.000    8442138    9013406     9086      9086          0   \n",
       "4     7.000    8374706          0     9086         0          0   \n",
       "\n",
       "   FLOW_DURATION_MILLISECONDS  Label  Attack  \n",
       "0                     4294966      0  Benign  \n",
       "1                     4176249      1   Theft  \n",
       "2                     4175916      0  Benign  \n",
       "3                     4175916      0  Benign  \n",
       "4                     4175916      0  Benign  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "my_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c073f02c-b25d-4465-8445-9c6ec4c3beee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total columns with only 1 unique value: 0\n"
     ]
    }
   ],
   "source": [
    "drop_cols = []\n",
    "for i in my_dataset.columns:\n",
    "    if len(my_dataset[i].unique())==1:\n",
    "        drop_cols.append(i)\n",
    "print(\"Total columns with only 1 unique value:\", len(drop_cols))\n",
    "my_dataset.drop(drop_cols, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14a6445d-a87d-4464-a5aa-a78102a5c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dataset.dropna(1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7240e764-ae56-41f4-a7d7-21f8290dec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset on train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test=train_test_split(my_dataset,test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d0a663d-bd7d-411c-827a-91effe203178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L4_SRC_PORT</th>\n",
       "      <th>L4_DST_PORT</th>\n",
       "      <th>PROTOCOL</th>\n",
       "      <th>L7_PROTO</th>\n",
       "      <th>IN_BYTES</th>\n",
       "      <th>OUT_BYTES</th>\n",
       "      <th>IN_PKTS</th>\n",
       "      <th>OUT_PKTS</th>\n",
       "      <th>TCP_FLAGS</th>\n",
       "      <th>FLOW_DURATION_MILLISECONDS</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180030.000000</td>\n",
       "      <td>180030.000000</td>\n",
       "      <td>180030.00000</td>\n",
       "      <td>180030.000000</td>\n",
       "      <td>1.800300e+05</td>\n",
       "      <td>1.800300e+05</td>\n",
       "      <td>180030.000000</td>\n",
       "      <td>180030.000000</td>\n",
       "      <td>180030.000000</td>\n",
       "      <td>1.800300e+05</td>\n",
       "      <td>180030.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>46550.677265</td>\n",
       "      <td>7975.248192</td>\n",
       "      <td>6.58182</td>\n",
       "      <td>8.989024</td>\n",
       "      <td>8.570278e+03</td>\n",
       "      <td>4.940851e+03</td>\n",
       "      <td>12.543276</td>\n",
       "      <td>5.736005</td>\n",
       "      <td>21.865861</td>\n",
       "      <td>3.475628e+06</td>\n",
       "      <td>0.976693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12016.939538</td>\n",
       "      <td>14132.240182</td>\n",
       "      <td>2.55893</td>\n",
       "      <td>35.045190</td>\n",
       "      <td>2.221175e+05</td>\n",
       "      <td>3.913169e+05</td>\n",
       "      <td>245.665646</td>\n",
       "      <td>169.866978</td>\n",
       "      <td>8.108470</td>\n",
       "      <td>1.660000e+06</td>\n",
       "      <td>0.150878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.800000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39210.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.278545e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47892.000000</td>\n",
       "      <td>1875.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.294966e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55307.000000</td>\n",
       "      <td>8009.000000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.120000e+02</td>\n",
       "      <td>4.000000e+01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>4.294967e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65535.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>9.519928e+06</td>\n",
       "      <td>1.513069e+08</td>\n",
       "      <td>9598.000000</td>\n",
       "      <td>13807.000000</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>4.294967e+06</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         L4_SRC_PORT    L4_DST_PORT      PROTOCOL       L7_PROTO  \\\n",
       "count  180030.000000  180030.000000  180030.00000  180030.000000   \n",
       "mean    46550.677265    7975.248192       6.58182       8.989024   \n",
       "std     12016.939538   14132.240182       2.55893      35.045190   \n",
       "min         0.000000       0.000000       1.00000       0.000000   \n",
       "25%     39210.000000      80.000000       6.00000       0.000000   \n",
       "50%     47892.000000    1875.000000       6.00000       0.000000   \n",
       "75%     55307.000000    8009.000000       6.00000       7.000000   \n",
       "max     65535.000000   65535.000000      17.00000     244.000000   \n",
       "\n",
       "           IN_BYTES     OUT_BYTES        IN_PKTS       OUT_PKTS  \\\n",
       "count  1.800300e+05  1.800300e+05  180030.000000  180030.000000   \n",
       "mean   8.570278e+03  4.940851e+03      12.543276       5.736005   \n",
       "std    2.221175e+05  3.913169e+05     245.665646     169.866978   \n",
       "min    2.800000e+01  0.000000e+00       1.000000       0.000000   \n",
       "25%    4.400000e+01  4.000000e+01       1.000000       1.000000   \n",
       "50%    4.400000e+01  4.000000e+01       1.000000       1.000000   \n",
       "75%    1.120000e+02  4.000000e+01       2.000000       1.000000   \n",
       "max    9.519928e+06  1.513069e+08    9598.000000   13807.000000   \n",
       "\n",
       "           TCP_FLAGS  FLOW_DURATION_MILLISECONDS          Label  \n",
       "count  180030.000000                1.800300e+05  180030.000000  \n",
       "mean       21.865861                3.475628e+06       0.976693  \n",
       "std         8.108470                1.660000e+06       0.150878  \n",
       "min         0.000000                0.000000e+00       0.000000  \n",
       "25%        22.000000                4.278545e+06       1.000000  \n",
       "50%        22.000000                4.294966e+06       1.000000  \n",
       "75%        22.000000                4.294967e+06       1.000000  \n",
       "max       214.000000                4.294967e+06       1.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split dataset on train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test=train_test_split(my_dataset,test_size=0.3, random_state=10)\n",
    "\n",
    "#Exploratory Analysis\n",
    "# Descriptive statistics\n",
    "train.describe()\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c60b4b0c-90be-45d5-8c38-d97f0ad47bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    175834\n",
       "0      4196\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Packet Attack Distribution\n",
    "train['Label'].value_counts()\n",
    "test['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c53a364-bbdc-4bdd-b51a-b2679619e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scalling numerical attributes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63e43ec6-c07d-4e6e-a43a-eb02261061d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract numerical attributes and scale it to have zero mean and unit variance  \n",
    "cols = train.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
    "sc_test = scaler.fit_transform(test.select_dtypes(include=['float64','int64']))\n",
    "# turn the result back to a dataframe\n",
    "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
    "sc_testdf = pd.DataFrame(sc_test, columns = cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f0e7e74-8edb-4cf7-9825-f205c776adf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# importing one hot encoder from sklearn \n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "# creating one hot encoder object \n",
    "onehotencoder = OneHotEncoder() \n",
    "trainDep = train['Label'].values.reshape(-1,1)\n",
    "trainDep = onehotencoder.fit_transform(trainDep).toarray()\n",
    "testDep = test['Label'].values.reshape(-1,1)\n",
    "testDep = onehotencoder.fit_transform(testDep).toarray()\n",
    "\n",
    "print (testDep)\n",
    "train_X=sc_traindf\n",
    "train_y=trainDep[:,0]\n",
    "\n",
    "test_X=sc_testdf\n",
    "test_y=testDep[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9004a9cc-1259-4d8e-b778-7c864e58438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier();\n",
    "\n",
    "# fit random forest classifier on the training set\n",
    "rfc.fit(train_X, train_y);\n",
    "\n",
    "# extract important features\n",
    "score = np.round(rfc.feature_importances_,3)\n",
    "importances = pd.DataFrame({'feature':train_X.columns,'importance':score})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c769d92a-5dc0-4d0e-8112-25eaa8fdff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recursive feature elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "import itertools\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# create the RFE model and select 10 attributes\n",
    "rfe = RFE(rfc, n_features_to_select=11)\n",
    "rfe = rfe.fit(train_X, train_y)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), train_X.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "\n",
    "selected_features\n",
    "\n",
    "a = [i[0] for i in feature_map]\n",
    "train_X = train_X.iloc[:,a]\n",
    "test_X = test_X.iloc[:,a]\n",
    "\n",
    "#Dataset Partition\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(train_X,train_y,train_size=0.70, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6dd1e398-d447-4b0c-9e97-c34570e39df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\bukola\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (0.23.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (1.43.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (58.0.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\bukola\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6dc62808-48fe-4df5-afea-0ccdb5fddfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Models\n",
    "#importing keras libraries and packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8964678-f938-43b7-8a46-41498d82a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting Models\n",
    "# Importing keras libraries and packahes\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a254f85f-d948-41d8-9737-cdb6769150ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "965de2bc-8c3f-45c8-bcda-a3598063e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "900ab82b-3f25-447f-8459-2f15ed994ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the second hidden layer\n",
    "classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd46a0ca-ce1a-44ee-8948-0c96df66375c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "74fd3ba5-1934-456a-a8c3-dbf8d20c14f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the ANN\n",
    "classifier.compile(optimizer ='adam' , loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4cb5487-d487-400d-a7fc-026c61e4101a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "29405/29405 [==============================] - 17s 557us/step - loss: 0.0045 - accuracy: 0.9997\n",
      "Epoch 2/30\n",
      "29405/29405 [==============================] - 16s 556us/step - loss: 6.7709e-05 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "29405/29405 [==============================] - 16s 550us/step - loss: 8.8821e-06 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "29405/29405 [==============================] - 16s 555us/step - loss: 2.0632e-08 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "29405/29405 [==============================] - 16s 553us/step - loss: 1.2667e-09 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "29405/29405 [==============================] - 16s 544us/step - loss: 2.2182e-10 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "29405/29405 [==============================] - 16s 552us/step - loss: 1.1284e-10 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "29405/29405 [==============================] - 16s 558us/step - loss: 8.3433e-11 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "29405/29405 [==============================] - 16s 553us/step - loss: 7.1248e-11 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "29405/29405 [==============================] - 16s 560us/step - loss: 5.9757e-11 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "29405/29405 [==============================] - 16s 548us/step - loss: 4.6775e-11 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "29405/29405 [==============================] - 16s 557us/step - loss: 4.3372e-11 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "29405/29405 [==============================] - 16s 556us/step - loss: 4.1373e-11 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "29405/29405 [==============================] - 17s 563us/step - loss: 3.9884e-11 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "29405/29405 [==============================] - 18s 606us/step - loss: 3.8757e-11 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "29405/29405 [==============================] - 18s 616us/step - loss: 3.7909e-11 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "29405/29405 [==============================] - 16s 550us/step - loss: 3.7620e-11 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "29405/29405 [==============================] - 16s 553us/step - loss: 3.7279e-11 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "29405/29405 [==============================] - 16s 545us/step - loss: 3.7179e-11 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "29405/29405 [==============================] - 16s 546us/step - loss: 3.7081e-11 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "29405/29405 [==============================] - 16s 545us/step - loss: 3.7211e-11 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "29405/29405 [==============================] - 16s 546us/step - loss: 3.7231e-11 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "29405/29405 [==============================] - 16s 550us/step - loss: 3.7437e-11 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "29405/29405 [==============================] - 16s 546us/step - loss: 3.7847e-11 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "29405/29405 [==============================] - 16s 546us/step - loss: 3.8029e-11 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "29405/29405 [==============================] - 16s 546us/step - loss: 3.8338e-11 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "29405/29405 [==============================] - 16s 545us/step - loss: 3.8767e-11 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "29405/29405 [==============================] - 16s 550us/step - loss: 3.1482e-11 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "29405/29405 [==============================] - 16s 548us/step - loss: 2.5350e-11 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "29405/29405 [==============================] - 16s 548us/step - loss: 2.5171e-11 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d17c2dea00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting thE ANN to the training set\n",
    "classifier.fit(X_train, Y_train, batch_size = 10, epochs = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5744879c-42fe-45c3-8a02-944a439b447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_train = (classifier.predict(X_train) > 0.5)\n",
    "K_test = (classifier.predict(X_test) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40a3efea-d6d7-4a13-b07c-606a24ee9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Predicting for test data\n",
    "pred_ann = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5ead3959-308d-4b82-ae3b-93f37f51cfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0297d226-8924-49f7-9044-96c6f0bdc522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 9, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 7, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer ='adam' , loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3be6fadd-9331-443c-a81b-5374ec17ccca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "26465/26465 [==============================] - 16s 583us/step - loss: 0.0061 - accuracy: 0.9997\n",
      "Epoch 2/30\n",
      "26465/26465 [==============================] - 16s 589us/step - loss: 6.5253e-05 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "26465/26465 [==============================] - 16s 587us/step - loss: 2.1460e-06 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "26465/26465 [==============================] - 15s 570us/step - loss: 2.1276e-06 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "26465/26465 [==============================] - 26s 1ms/step - loss: 7.1326e-05 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 5.6505e-05 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "26465/26465 [==============================] - 40s 2ms/step - loss: 1.6223e-06 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 1.3526e-07 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 7.4839e-09 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 1.6821e-09 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.5507e-10 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "26465/26465 [==============================] - 20s 749us/step - loss: 1.2126e-10 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "26465/26465 [==============================] - 22s 820us/step - loss: 7.5336e-11 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "26465/26465 [==============================] - 20s 767us/step - loss: 5.4070e-11 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "26465/26465 [==============================] - 16s 606us/step - loss: 4.2023e-11 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "26465/26465 [==============================] - 27s 1ms/step - loss: 3.4527e-11 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "26465/26465 [==============================] - 22s 825us/step - loss: 2.8541e-11 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "26465/26465 [==============================] - 18s 687us/step - loss: 2.4191e-11 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "26465/26465 [==============================] - 22s 833us/step - loss: 2.1278e-11 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "26465/26465 [==============================] - 30s 1ms/step - loss: 1.9013e-11 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "26465/26465 [==============================] - 30s 1ms/step - loss: 1.7196e-11 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "26465/26465 [==============================] - 18s 680us/step - loss: 1.5715e-11 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "26465/26465 [==============================] - 16s 604us/step - loss: 1.4484e-11 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "26465/26465 [==============================] - 17s 624us/step - loss: 1.3448e-11 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "26465/26465 [==============================] - 22s 847us/step - loss: 1.2585e-11 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 1.1868e-11 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 1.1251e-11 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 1.0713e-11 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 1.0243e-11 - accuracy: 1.0000 0s\n",
      "Epoch 30/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 9.8177e-12 - accuracy: 1.0000\n",
      "2941/2941 [==============================] - 4s 1ms/step - loss: 9.3819e-12 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "26465/26465 [==============================] - 50s 2ms/step - loss: 0.0057 - accuracy: 0.9997\n",
      "Epoch 2/30\n",
      "26465/26465 [==============================] - 50s 2ms/step - loss: 1.3910e-04 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 2.8825e-06 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 2.3737e-08 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 4.5366e-09 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "26465/26465 [==============================] - 49s 2ms/step - loss: 8.4520e-10 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "26465/26465 [==============================] - 49s 2ms/step - loss: 3.4898e-10 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 2.1121e-10 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 1.5850e-10 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 1.3377e-10 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 1.2272e-10 - accuracy: 1.0000 0s - loss: 1.2290e-10 - \n",
      "Epoch 12/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 1.1600e-10 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 1.0121e-10 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 9.7450e-11 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 9.5211e-11 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 9.3505e-11 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 9.2115e-11 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 9.1008e-11 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 9.0462e-11 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.9944e-11 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "26465/26465 [==============================] - 32s 1ms/step - loss: 8.9641e-11 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.9308e-11 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.9141e-11 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 7.5769e-11 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 7.5215e-11 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 7.4917e-11 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 7.4664e-11 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 7.4397e-11 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 7.4181e-11 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 7.4005e-11 - accuracy: 1.0000\n",
      "2941/2941 [==============================] - 4s 1ms/step - loss: 7.3616e-11 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "26465/26465 [==============================] - 50s 2ms/step - loss: 0.0082 - accuracy: 0.9982\n",
      "Epoch 2/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0357e-04 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.8923e-04 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.9396e-04 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.9840e-04 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0156e-04 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0213e-04 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 3.0078e-04 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0232e-04 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0117e-04 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0143e-04 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0886e-04 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.1025e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.2419e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.2320e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.2047e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 3.1682e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.2365e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.1919e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.2026e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.1645e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.1648e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.1953e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "26465/26465 [==============================] - 49s 2ms/step - loss: 3.1620e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "26465/26465 [==============================] - 55s 2ms/step - loss: 3.1216e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "26465/26465 [==============================] - 50s 2ms/step - loss: 3.0765e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0690e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.0771e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.0994e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.3197e-04 - accuracy: 1.0000\n",
      "2941/2941 [==============================] - 4s 1ms/step - loss: 3.8514e-06 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 0.0080 - accuracy: 0.9981\n",
      "Epoch 2/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.2008e-04 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 1.1114e-04 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 4.2241e-05 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 2.8713e-05 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.2714e-06 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 2.6005e-07 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.2755e-08 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 5.8900e-09 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.5877e-09 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 1.6626e-09 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 1.0942e-09 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 8.9347e-10 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.8295e-10 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 8.7755e-10 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 8.7435e-10 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.7226e-10 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 8.7078e-10 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6963e-10 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6879e-10 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6805e-10 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6750e-10 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6703e-10 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 8.6665e-10 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6630e-10 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6597e-10 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6577e-10 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6553e-10 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6530e-10 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 8.6513e-10 - accuracy: 1.0000\n",
      "2941/2941 [==============================] - 4s 1ms/step - loss: 8.2015e-10 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "26465/26465 [==============================] - 41s 2ms/step - loss: 0.0061 - accuracy: 0.9996\n",
      "Epoch 2/30\n",
      "26465/26465 [==============================] - 40s 2ms/step - loss: 1.0531e-04 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 1.1080e-06 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "26465/26465 [==============================] - 38s 1ms/step - loss: 2.8489e-07 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "26465/26465 [==============================] - 41s 2ms/step - loss: 5.7890e-08 - accuracy: 1.0000 0s - loss: 5.8327e-08 - ac\n",
      "Epoch 6/30\n",
      "26465/26465 [==============================] - 41s 2ms/step - loss: 9.5674e-09 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 1.6476e-09 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 4.9395e-10 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 2.5395e-10 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 1.7704e-10 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 1.4024e-10 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 1.2298e-10 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 1.1373e-10 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 1.0771e-10 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 9.9039e-11 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 9.3853e-11 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 9.1546e-11 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 8.9778e-11 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 8.8339e-11 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 8.7212e-11 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.6298e-11 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.5503e-11 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.4946e-11 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.4500e-11 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.4128e-11 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.0267e-11 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 7.6872e-11 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 7.6565e-11 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 7.6325e-11 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 7.6056e-11 - accuracy: 1.0000\n",
      "2941/2941 [==============================] - 4s 1ms/step - loss: 7.7510e-11 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "26465/26465 [==============================] - 40s 1ms/step - loss: 0.0049 - accuracy: 0.9998\n",
      "Epoch 2/30\n",
      "26465/26465 [==============================] - 40s 1ms/step - loss: 1.9470e-06 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "26465/26465 [==============================] - 40s 1ms/step - loss: 1.9340e-07 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "26465/26465 [==============================] - 40s 2ms/step - loss: 4.8045e-08 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 1.1545e-08 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "26465/26465 [==============================] - 40s 1ms/step - loss: 2.5641e-09 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 6.9692e-10 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 3.0065e-10 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 1.9769e-10 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 1.5040e-10 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 1.3116e-10 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 1.1171e-10 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 1.0729e-10 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 1.0627e-10 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 1.0131e-10 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "26465/26465 [==============================] - 39s 1ms/step - loss: 8.7294e-11 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "26465/26465 [==============================] - 40s 2ms/step - loss: 8.5724e-11 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.5298e-11 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.4846e-11 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.5353e-11 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.6028e-11 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.6959e-11 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 8.8287e-11 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 8.7759e-11 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 7.2061e-11 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 7.1758e-11 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 7.1575e-11 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 7.1550e-11 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 7.1648e-11 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 7.1766e-11 - accuracy: 1.0000\n",
      "2941/2941 [==============================] - 4s 1ms/step - loss: 7.7226e-11 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 0.0065 - accuracy: 0.9996\n",
      "Epoch 2/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 1.6347e-04 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 1.1963e-06 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 1.4978e-07 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 1.9495e-08 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 2.6416e-09 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 5.0736e-10 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 2.0928e-10 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 1.2675e-10 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 9.7657e-11 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "26465/26465 [==============================] - 37s 1ms/step - loss: 8.3602e-11 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 7.2445e-11 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "26465/26465 [==============================] - 42s 2ms/step - loss: 6.2141e-11 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "26465/26465 [==============================] - 42s 2ms/step - loss: 5.7861e-11 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "26465/26465 [==============================] - 42s 2ms/step - loss: 5.4806e-11 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "26465/26465 [==============================] - 42s 2ms/step - loss: 5.2765e-11 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "26465/26465 [==============================] - 42s 2ms/step - loss: 5.1263e-11 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 5.0283e-11 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 4.9595e-11 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 4.9309e-11 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 4.9102e-11 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 4.7798e-11 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 4.0781e-11 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 4.0238e-11 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.9767e-11 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.9352e-11 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.8993e-11 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "26465/26465 [==============================] - 40s 2ms/step - loss: 3.8675e-11 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "26465/26465 [==============================] - 36s 1ms/step - loss: 3.8400e-11 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.8152e-11 - accuracy: 1.0000\n",
      "2941/2941 [==============================] - 4s 1ms/step - loss: 3.3880e-11 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 0.0081 - accuracy: 0.9983\n",
      "Epoch 2/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 2.9517e-04 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 2.8625e-04 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 2.9125e-04 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 2.9161e-04 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.1388e-04 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.1073e-04 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.5667e-04 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.5201e-04 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.4735e-04 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.4112e-04 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.3387e-04 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.5077e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.4470e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.3867e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.7274e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.6938e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.6437e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.6300e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.5403e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.4678e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.4030e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.3525e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.2879e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.2627e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.2116e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.2817e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 3.2508e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.2379e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "26465/26465 [==============================] - 44s 2ms/step - loss: 3.2182e-04 - accuracy: 1.0000\n",
      "2941/2941 [==============================] - 4s 1ms/step - loss: 5.7648e-06 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "26465/26465 [==============================] - 51s 2ms/step - loss: 0.0064 - accuracy: 0.9992\n",
      "Epoch 2/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 3.3752e-04 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.2699e-04 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.0924e-04 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0577e-04 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0250e-04 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "26465/26465 [==============================] - 49s 2ms/step - loss: 3.7651e-04 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 3.2678e-04 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0479e-04 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 4.0673e-04 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.3669e-04 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 2.9356e-04 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.4491e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "26465/26465 [==============================] - 49s 2ms/step - loss: 3.0968e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.3574e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.3225e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.4378e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 3.1365e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "26465/26465 [==============================] - 49s 2ms/step - loss: 3.1899e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "26465/26465 [==============================] - 53s 2ms/step - loss: 3.1376e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "26465/26465 [==============================] - 49s 2ms/step - loss: 3.1738e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.2088e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.2309e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.1670e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.1542e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 3.0349e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.2475e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.0447e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 3.1262e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 3.1202e-04 - accuracy: 1.0000\n",
      "2941/2941 [==============================] - 4s 1ms/step - loss: 4.0328e-06 - accuracy: 1.0000\n",
      "Epoch 1/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 0.0083 - accuracy: 0.9982\n",
      "Epoch 2/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.4580e-04 - accuracy: 1.0000\n",
      "Epoch 3/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 2.3061e-04 - accuracy: 1.0000\n",
      "Epoch 4/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.4776e-04 - accuracy: 1.0000\n",
      "Epoch 5/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.7776e-04 - accuracy: 1.0000\n",
      "Epoch 6/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 2.7519e-04 - accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "26465/26465 [==============================] - 54s 2ms/step - loss: 2.7386e-04 - accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 2.7688e-04 - accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.8229e-04 - accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "26465/26465 [==============================] - 43s 2ms/step - loss: 2.7775e-04 - accuracy: 1.0000\n",
      "Epoch 11/30\n",
      "26465/26465 [==============================] - 49s 2ms/step - loss: 2.7361e-04 - accuracy: 1.0000\n",
      "Epoch 12/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 2.7431e-04 - accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.6985e-04 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.6738e-04 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 2.7335e-04 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "26465/26465 [==============================] - 49s 2ms/step - loss: 2.8935e-04 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "26465/26465 [==============================] - 51s 2ms/step - loss: 2.9459e-04 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 2.9971e-04 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 2.9631e-04 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.9072e-04 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.2759e-04 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 3.2118e-04 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.1480e-04 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 3.0870e-04 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "26465/26465 [==============================] - 45s 2ms/step - loss: 3.0483e-04 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 2.9881e-04 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "26465/26465 [==============================] - 54s 2ms/step - loss: 2.9696e-04 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "26465/26465 [==============================] - 48s 2ms/step - loss: 2.9337e-04 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "26465/26465 [==============================] - 47s 2ms/step - loss: 2.9719e-04 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "26465/26465 [==============================] - 46s 2ms/step - loss: 2.9325e-04 - accuracy: 1.0000\n",
      "2941/2941 [==============================] - 4s 1ms/step - loss: 6.5004e-04 - accuracy: 0.9999\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 30)\n",
    "scores = cross_val_score(estimator = classifier, X = X_train, y= Y_train, cv = 10, n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73976ee7-9c03-4a7b-97e4-95f2209fc9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5154ebf0-3f99-426e-a99d-9521587d9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(train_X,train_y,train_size=0.70, random_state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06f98f4b-c863-4b30-a5c7-f5e2364b245e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99999899e-01, 1.00849528e-07]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(random_state=1, max_iter=300).fit(X_train, Y_train)\n",
    "clf.predict_proba(X_test[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8541aacc-b99f-4a12-a5d8-29c2f2b92f6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1fb300ac-0ef9-4f13-9c65-11842baf1db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7173b732-279e-469b-a8c3-40548632fee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== ANN Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.99999659921782\n",
      "\n",
      "Model Accuracy:\n",
      " 1.0\n",
      "\n",
      "Confusion matrix:\n",
      " [[287283      0]\n",
      " [     0   6766]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    287283\n",
      "         1.0       1.00      1.00      1.00      6766\n",
      "\n",
      "    accuracy                           1.00    294049\n",
      "   macro avg       1.00      1.00      1.00    294049\n",
      "weighted avg       1.00      1.00      1.00    294049\n",
      "\n",
      "\n",
      "Mean Absolute Error:\n",
      " 0.0\n",
      "\n",
      "R2_score:\n",
      " 1.0\n",
      "\n",
      "F1_score:\n",
      " 1.0\n",
      "\n",
      "Testing time:  114.9535596370697\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Models\n",
    "from sklearn import metrics\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "models = []\n",
    "models.append(('ANN', clf))\n",
    "\n",
    "\n",
    "for i, v in models:\n",
    "    start_time = time.time()\n",
    "    scores = cross_val_score(v, X_train, Y_train, cv=10)\n",
    "    accuracy = metrics.accuracy_score(Y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(Y_train, v.predict(X_train))\n",
    "    MAE = metrics.mean_absolute_error(Y_train, v.predict(X_train))\n",
    "    R2_Score = metrics.r2_score(Y_train, v.predict(X_train))\n",
    "    F1_Score = metrics.f1_score(Y_train, v.predict(X_train))\n",
    "    end_time = time.time()\n",
    "    print()\n",
    "    print('============================== {} Model Evaluation =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()\n",
    "    print(\"Mean Absolute Error:\" \"\\n\", MAE) \n",
    "    print()\n",
    "    print(\"R2_score:\" \"\\n\", R2_Score ) \n",
    "    print()\n",
    "    print(\"F1_score:\" \"\\n\", F1_Score ) \n",
    "    print()\n",
    "    print(\"Testing time: \",end_time-start_time)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc3ae50e-20ac-4821-a20a-26387717b297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== ANN Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 1.0\n",
      "\n",
      "Confusion matrix:\n",
      " [[123124      0]\n",
      " [     0   2897]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    123124\n",
      "         1.0       1.00      1.00      1.00      2897\n",
      "\n",
      "    accuracy                           1.00    126021\n",
      "   macro avg       1.00      1.00      1.00    126021\n",
      "weighted avg       1.00      1.00      1.00    126021\n",
      "\n",
      "\n",
      "Mean Absolute Error:\n",
      " 0.0\n",
      "\n",
      "R2_score:\n",
      " 1.0\n",
      "\n",
      "F1_score:\n",
      " 1.0\n",
      "\n",
      "Testing time:  1.2198066711425781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Validate Models\n",
    "\n",
    "for i, v in models:\n",
    "    start_time = time.time()\n",
    "    accuracy = metrics.accuracy_score(Y_test, v.predict(X_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_test, v.predict(X_test))\n",
    "    classification = metrics.classification_report(Y_test, v.predict(X_test))\n",
    "    MAE = metrics.mean_absolute_error(Y_test, v.predict(X_test))\n",
    "    R2_Score = metrics.r2_score(Y_test, v.predict(X_test))\n",
    "    F1_Score = metrics.f1_score(Y_test, v.predict(X_test))\n",
    "    end_time = time.time()\n",
    "    print()\n",
    "    print('============================== {} Model Test Results =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()\n",
    "    print(\"Mean Absolute Error:\" \"\\n\", MAE)  \n",
    "    print()\n",
    "    print(\"R2_score:\" \"\\n\", R2_Score ) \n",
    "    print()\n",
    "    print(\"F1_score:\" \"\\n\", F1_Score ) \n",
    "    print()\n",
    "    print(\"Testing time: \",end_time-start_time)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9fdef-b3ce-4e72-8001-5fcdc005029b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
